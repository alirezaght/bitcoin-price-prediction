{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezaght/bitcoin-price-prediction/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTizkxhGhQUO"
      },
      "source": [
        "## Download historical data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm downloading btc price from https://www.cryptodatadownload.com/cdd/Bitstamp_BTCUSD_d.csv\n",
        "\n",
        "and eth price from https://www.cryptodatadownload.com/cdd/Bitstamp_ETHUSD_d.csv\n",
        "\n",
        "and gold price from https://www.nasdaq.com/market-activity/commodities/gc:cmx/historical\n",
        "\n",
        "and oil price from https://www.nasdaq.com/market-activity/commodities/cl:nmx/historical"
      ],
      "metadata": {
        "id": "f3rVWvfqxvru"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woma8RK6fTAu",
        "outputId": "713c6325-1533-4c98-dd6b-60dda7b65b14"
      },
      "source": [
        "!gdown 11IppFUtMJ6CSs4AAc_mAz8DpIrESY03H\n",
        "!gdown 1Vx3NGEQNssg03QXXlIjtFDjMC_8Vm9Hr\n",
        "!gdown 1Ih-kXFor9L3YSQYJPdh7XRnuqbPt34Hv\n",
        "!gdown 1CucFfrWKJJGngd8PaZXv1ygnFpNnyeJl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=11IppFUtMJ6CSs4AAc_mAz8DpIrESY03H\n",
            "To: /content/gold-price.csv\n",
            "100% 116k/116k [00:00<00:00, 26.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Vx3NGEQNssg03QXXlIjtFDjMC_8Vm9Hr\n",
            "To: /content/btc-price.csv\n",
            "100% 285k/285k [00:00<00:00, 19.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ih-kXFor9L3YSQYJPdh7XRnuqbPt34Hv\n",
            "To: /content/eth-price.csv\n",
            "100% 186k/186k [00:00<00:00, 24.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CucFfrWKJJGngd8PaZXv1ygnFpNnyeJl\n",
            "To: /content/oil-price.csv\n",
            "100% 109k/109k [00:00<00:00, 28.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FngpvB2YhpdN"
      },
      "source": [
        "# Preprocess *data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twJoe2OJihM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbda6950-f995-4871-c1d4-bff296280b1b"
      },
      "source": [
        "from tensorflow.python.ops.ragged.row_partition import np\n",
        "from functools import reduce \n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import math\n",
        "\n",
        "gold_csv = pd.read_csv('gold-price.csv', keep_default_na=False)\n",
        "btc_csv = pd.read_csv('btc-price.csv', keep_default_na=False)\n",
        "eth_csv = pd.read_csv('eth-price.csv', keep_default_na=False)\n",
        "oil_csv = pd.read_csv('oil-price.csv', keep_default_na=False)\n",
        "\n",
        "\n",
        "\n",
        "feed_days = 90\n",
        "indicators = 5\n",
        "evaluate_days = 30\n",
        "\n",
        "oils = {}\n",
        "# oils_vols = {}\n",
        "\n",
        "for i in range(0, len(oil_csv)):  \n",
        "  # if oil_csv.iloc[i, 2] == \"N/A\":\n",
        "    # continue\n",
        "  oil_time = datetime.strptime(oil_csv.iloc[i, 0], \"%m/%d/%Y\").timestamp()\n",
        "  oils[oil_time] = float(oil_csv.iloc[i, 3])  \n",
        "  # oils_vols[oil_time] = float(oil_csv.iloc[i, 2])\n",
        "\n",
        "original = []\n",
        "\n",
        "index = 1\n",
        "for i in range(0, len(gold_csv)):  \n",
        "  if i >= len(btc_csv) or i >= len(eth_csv):\n",
        "    break\n",
        "  gold_time = datetime.strptime(gold_csv.iloc[i, 0], \"%m/%d/%Y\").timestamp()\n",
        "  if gold_time not in oils:\n",
        "    continue\n",
        "  \n",
        "  oil_price = oils[gold_time]\n",
        "  # oil_vol = oils_vols[gold_time]\n",
        "  gold_price = float(gold_csv.iloc[i, 3]) # open price  \n",
        "  # if gold_csv.iloc[i, 2] == \"N/A\":\n",
        "    # continue\n",
        "  # gold_vol = float(gold_csv.iloc[i, 2])   \n",
        "  while True: \n",
        "    if index >= len(btc_csv) or index >= len(eth_csv):\n",
        "      break   \n",
        "    btc_time = float(btc_csv.iloc[index].name[0])\n",
        "    if btc_time < gold_time:      \n",
        "      break   \n",
        "    btc_price = float(btc_csv.iloc[index].name[3]) # open price        \n",
        "    btc_vol = float(btc_csv.iloc[index][0]) \n",
        "    eth_price = float(eth_csv.iloc[index].name[3]) # open price    \n",
        "    # eth_vol = float(eth_csv.iloc[index][0]) \n",
        "    index += 1\n",
        "    original.append([btc_price, btc_vol, gold_price, eth_price, oil_price])\n",
        "original = np.array(original[::-1])\n",
        "\n",
        "print(\"Length of btc data: \", len(btc_csv))\n",
        "print(\"Length of eth data: \", len(eth_csv))\n",
        "print(\"Length of oil data: \", len(oil_csv))\n",
        "print(\"Length of gold data: \", len(gold_csv))\n",
        "print(\"Length of data: \", len(original))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of btc data:  2926\n",
            "Length of eth data:  1849\n",
            "Length of oil data:  2547\n",
            "Length of gold data:  2547\n",
            "Length of data:  1848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scaling"
      ],
      "metadata": {
        "id": "gNyx0sxnAOa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "data = scaler.fit_transform(original)\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "for i in range(feed_days, len(data)):\n",
        "  x_train.append(np.reshape(data[i - feed_days: i], (1, feed_days * indicators)))\n",
        "  y_train.append(data[i][0])\n",
        "\n",
        "\n",
        "x_train = np.reshape(x_train, (len(x_train), feed_days, indicators))\n",
        "y_train = np.reshape(y_train, (len(y_train)))\n"
      ],
      "metadata": {
        "id": "UyVhr_olAYPy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx70byQ7vbEL"
      },
      "source": [
        "# Build Model and Train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from keras import backend as K"
      ],
      "metadata": {
        "id": "vpUY829iDqbi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNh8mYgaIuAw",
        "outputId": "b5e1ca69-6e34-47e7-8b50-c6b9f7a94e30"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "alpha = 1000\n",
        "direction = None\n",
        "def custom_loss(y, y_pred):\n",
        "  global direction\n",
        "  t = y * y_pred\n",
        "  \n",
        "  indices = tf.where(t < 0)[:, 0]   \n",
        "  indices = tf.reshape(indices, (len(indices), 1))\n",
        "  if direction is None:\n",
        "    direction = tf.Variable(tf.ones_like(y_pred), dtype='float32')     \n",
        "  updates = K.cast(tf.ones_like(indices), dtype='float32')\n",
        "  updates = updates * alpha\n",
        "  if len(indices) > 0:        \n",
        "    direction.assign(tf.tensor_scatter_nd_update(direction, indices, updates))\n",
        "  else:    \n",
        "    direction.assign(tf.ones_like(y))\n",
        "  \n",
        "\n",
        "  custom_loss = K.mean(tf.multiply(K.square(y - y_pred), direction), axis=-1)\n",
        "  return custom_loss"
      ],
      "metadata": {
        "id": "q6VCc62ICCKf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "awcTphlmvfC3",
        "outputId": "efc874ba-e078-473d-a7c4-a042957397e9"
      },
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(layers.LSTM(128, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
        "model.add(layers.Dropout(0.2))\n",
        "\n",
        "model.add(layers.LSTM(128, return_sequences=True))\n",
        "model.add(layers.Dropout(0.2))\n",
        "\n",
        "model.add(layers.LSTM(64, return_sequences=True))\n",
        "model.add(layers.Dropout(0.2))\n",
        "\n",
        "model.add(layers.LSTM(64, return_sequences=True))\n",
        "model.add(layers.Dropout(0.2))\n",
        "\n",
        "model.add(layers.LSTM(32, return_sequences=True))\n",
        "model.add(layers.Dropout(0.2))\n",
        "\n",
        "model.add(layers.LSTM(32))\n",
        "model.add(layers.Dropout(0.2))\n",
        "\n",
        "model.add(layers.Dense(units = 32, activation=\"relu\"))\n",
        "\n",
        "model.add(layers.Dense(units = 1))\n",
        "model.compile(optimizer=\"adam\", loss=custom_loss)\n",
        "model.fit(x_train[0: len(x_train) - evaluate_days], y_train[0: len(y_train) - evaluate_days], epochs=30, batch_size=batch_size)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "Yes [32 1] [32 1] [32 1]\n",
            " 1/54 [..............................] - ETA: 50:58 - loss: 168.7411Yes [1 1] [1 1] [32 1]\n",
            "17/54 [========>.....................] - ETA: 16s - loss: 15.4391"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-12e816ff9347>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mevaluate_days\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mevaluate_days\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZEHExlI9RH4"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S483Ugmt9UUy"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "predict_days = 30\n",
        "\n",
        "x = np.array([])\n",
        "x = np.append(x, original[len(original) - feed_days - evaluate_days: len(original) - evaluate_days])\n",
        "x = np.reshape(x, (feed_days, indicators))\n",
        "x = scaler.transform(x)\n",
        "x = np.reshape(x, (1, feed_days, indicators))\n",
        "res_array = np.array([])\n",
        "y_array = np.array([])\n",
        "for i in range(1, predict_days):\n",
        "  res = scaler.inverse_transform(np.reshape(np.array([model.predict(x)[0], 0, 0, 0, 0]), (1, indicators)))\n",
        "  y_array = np.append(y_array, res[0][0])\n",
        "  res_array = np.append(res_array, res[0][0])\n",
        "  res_array = np.append(res_array, original[len(original) - 1 - evaluate_days][1:])\n",
        "  res_array = np.reshape(res_array, (i, indicators))  \n",
        "  x = np.append(original[len(original) - feed_days - evaluate_days + i: len(original) - evaluate_days], res_array, axis = 0)    \n",
        "  x = scaler.transform(x)\n",
        "  x = np.reshape(x, (1, feed_days, indicators))\n",
        "\n",
        "e_array = np.array([])\n",
        "\n",
        "\n",
        "if evaluate_days > 0:\n",
        "  for i in range(0, evaluate_days):\n",
        "    e_array = np.append(e_array, original[len(original) - evaluate_days + i][0])\n",
        "  plt.figure(1).gca().plot(y_array, color=\"green\")\n",
        "  plt.figure(2).gca().plot(e_array, color=\"red\")\n",
        "else:\n",
        "  plt.plot(y_array, color='green')\n",
        "print(\"End Prediction:\", (y_array[len(y_array) - 1] - y_array[0])/y_array[0], y_array[0], y_array[len(y_array) - 1])\n",
        "if evaluate_days > 0:  \n",
        "  print(\"Eval Prediction:\", (e_array[len(e_array) - 1] - e_array[0])/e_array[0], e_array[0], e_array[len(e_array) - 1])\n",
        "print(\"Min:\", (min(y_array) - y_array[0])/y_array[0], min(y_array))\n",
        "if evaluate_days > 0:\n",
        "  print(\"Eval Min:\", (min(e_array) - e_array[0])/e_array[0], min(e_array))  \n",
        "print(\"Max:\", (max(y_array) - y_array[0])/y_array[0], max(y_array))\n",
        "if evaluate_days > 0:\n",
        "  print(\"Eval Max:\", (max(e_array) - e_array[0])/e_array[0], max(e_array))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SoVe0DS7uiE0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}